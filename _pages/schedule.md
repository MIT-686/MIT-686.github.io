---
layout: page
title: Schedule
permalink: /schedule
---
## UNIVERSITY BREAKS AND IMPORTANT DATES
Please visit the [MIT Registrar Calendar](https://registrar.mit.edu/calendar) for the latest dates:
- **Sept 4 (Wed)**: Semester begins
- **Sept 13 (Fri)**: Last day for seniors and grad students to change H1 subjects to/from P/D/F
- **Sept 20 (Fri)**: Student holiday (no classes)
- **Oct 14 (Mon)**: Indigenous People's Day (no classes)
- **Nov 11 (Mon)**: Veteran's Day (no classes)
- **Nov 20 (Wed)**: Drop date. Last day to cancel full-term subjects.
- **Nov 28 (Thurs) - Nov 29 (Fri)**: Thanksgiving Break
- **Dec 11 (Wed)**: Last day of classes
- **Dec 16 (Mon) - Dec 20 (Fri)**: Exam Period (no classes)

## OUR CLASS
- Lectures are on **Tuesdays** and **Thursdays** at 11am-12:30am in 32.123
	- first lecture is on **Sept 5 (Thurs)**.
	- earlier lectures will mostly concern representation and _Deep Learning models_
	- later lectures will include guest lectures about particular _NLP Problems/Tasks_
	- the last content-based lecture will be **Dec 3 (Tues)**
	- we will <span style="background-color: #FACCCC">not have class on Oct 15 (Tues) and Nov 28 (Thurs)</span>, due to university breaks
	- **Final Presentations** will be on **Dec 5 (Thurs) and Dec 10 (Tues)**
- **Homeworks** are due <span style="background-color: #FFFF00">(Thursdays at 11:59pm EST)</span> and you will have roughly 2 weeks to complete them.
- **Research Projects** will span 12 weeks of the semester, with several deliverables due throughout

## LECTURES
- Lecture 1: Introduction + ML Basics
- Lecture 2: Classification (linear models, neural nets)
- Lecture 3: Sequence models 1 (ngrams, log-linear LMs, word2vec)
- Lecture 4: Sequence models 2 (RNNs)
- Lecture 5: Sequence models 3 (seq2seq + attention)
- Lecture 6: Transformers
- Lecture 7: Pretraining 1 (BERT and GPT)
- Lecture 8: Pretraining 2 (SFT and RLHF)
- Lecture 9: Efficient training (MoE, quantization, LoRA)
- Lecture 10: Doing research
- Lecture 11: Decoding 1 (prompting, CoT, and agents)
- Lecture 12: Decoding 2 (search and sampling)
- Lecture 13: Multimodality
- Lecture 14: Midterm review
- Lecture 15: Midterm
- Lecture 16: Beyond transformers (SSMs, Mamba, ...)
- Lecture 17: NLP Engineering
- Lecture 18: Interpretability
- Lecture 19: Guest Lecture: Speech
- Lecture 20: Struct pred
- Lecture 21: Guest Lecture: Intellectual property (SERC)
- Lecture 22: Bias & fairness
- Lecture 23: Human language processing
- Lecture 24: Conclusion


